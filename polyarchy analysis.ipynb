{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install numpy scipy pandas seaborn networkx GraphHierarchy xlrd openpyxl plotly nbformat\n",
    "\n",
    "https://stackoverflow.com/questions/1871549/determine-if-python-is-running-inside-virtualenv\n",
    "https://stackoverflow.com/questions/32092310/within-ipython-how-to-get-the-path-of-the-python-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPython Kernel --> ['C:\\\\anaconda3\\\\envs\\\\ling\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\Babak Ravandi\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-11404ad8-9596-456d-9fe8-9ba7e6e74ef3.json']\n",
      "Environment --> C:\\anaconda3\\envs\\ling\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('iPython Kernel -->', sys.argv)\n",
    "print('Environment -->', sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\ling\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\anaconda3\\envs\\ling\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\anaconda3\\envs\\ling\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "import GraphHierarchy as gh\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "'''\n",
    "This layout algorithm requires installin graphviz\n",
    "https://pygraphviz.github.io/documentation/stable/install.html\n",
    "'''\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "\n",
    "def save_xls(dfs_dict, xls_path, open=False):\n",
    "    if type(dfs_dict) is not dict:\n",
    "        dfs_dict = {'sheet1': dfs_dict}\n",
    "    \n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for df_name, df in dfs_dict.items():\n",
    "            df.to_excel(writer, df_name)\n",
    "        writer.save()\n",
    "\n",
    "    if open is True:\n",
    "        os.system('start EXCEL.EXE \"{}\"'.format(os.path.abspath(xls_path)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Mistake Duplicate Edges & Add Frequency\n",
    "\n",
    "THe only exception of having multiple interactions between a source and target is in 17th century as below. ALl other centuries must have only a single interaction (type of edge) between two nodes.\n",
    "\n",
    "Source:'PR ze'\t |\tTarget: 'IV werden'   |   Interactions: {PP, VP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_dir = \"D:/GoogleDrive/Research/Linguistic project/German/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Cent: 11  Path: /01 Mittelhochdeutsch middle high/11_cent.xlsx\n",
      "num edges in excel: 971  num network edges: 732\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//01 Mittelhochdeutsch middle high/11_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: 12  Path: /01 Mittelhochdeutsch middle high/12_cent.xlsx\n",
      "num edges in excel: 1195  num network edges: 822\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//01 Mittelhochdeutsch middle high/12_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: 13  Path: /01 Mittelhochdeutsch middle high/13_cent.xlsx\n",
      "num edges in excel: 2501  num network edges: 1362\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//01 Mittelhochdeutsch middle high/13_cent_freq.xlsx\n",
      "Interaction count > 1 --> 1\n",
      "------------ Cent: E14  Path: /01 Mittelhochdeutsch middle high/14E_cent.xlsx\n",
      "num edges in excel: 2345  num network edges: 1345\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//01 Mittelhochdeutsch middle high/14E_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: L14  Path: /02 Fruhneuhochdeutsch early new high/14L_cent.xlsx\n",
      "num edges in excel: 2518  num network edges: 1603\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//02 Fruhneuhochdeutsch early new high/14L_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: 15  Path: /02 Fruhneuhochdeutsch early new high/15_cent.xlsx\n",
      "num edges in excel: 2228  num network edges: 1426\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//02 Fruhneuhochdeutsch early new high/15_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: 16  Path: /02 Fruhneuhochdeutsch early new high/16_cent.xlsx\n",
      "num edges in excel: 3363  num network edges: 2461\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//02 Fruhneuhochdeutsch early new high/16_cent_freq.xlsx\n",
      "Interaction count > 1 --> 0\n",
      "------------ Cent: 17  Path: /02 Fruhneuhochdeutsch early new high/17_cent.xlsx\n",
      "num edges in excel: 3940  num network edges: 3081\n",
      "   EXPORTED --> D:/GoogleDrive/Research/Linguistic project/German/data//02 Fruhneuhochdeutsch early new high/17_cent_freq.xlsx\n",
      "Interaction count > 1 --> 1\n"
     ]
    }
   ],
   "source": [
    "save_freq_files = True\n",
    "\n",
    "path_networks_NO_FREQ = OrderedDict()\n",
    "\n",
    "path_networks_NO_FREQ['11'] = \"/01 Mittelhochdeutsch middle high/11_cent.xlsx\" \n",
    "path_networks_NO_FREQ['12'] = \"/01 Mittelhochdeutsch middle high/12_cent.xlsx\"\n",
    "path_networks_NO_FREQ['13'] = \"/01 Mittelhochdeutsch middle high/13_cent.xlsx\"\n",
    "path_networks_NO_FREQ['E14'] = \"/01 Mittelhochdeutsch middle high/14E_cent.xlsx\" # Early\n",
    "\n",
    "path_networks_NO_FREQ['L14'] = '/02 Fruhneuhochdeutsch early new high/14L_cent.xlsx' # Late\n",
    "path_networks_NO_FREQ['15'] = '/02 Fruhneuhochdeutsch early new high/15_cent.xlsx'\n",
    "path_networks_NO_FREQ['16'] = '/02 Fruhneuhochdeutsch early new high/16_cent.xlsx'\n",
    "path_networks_NO_FREQ['17'] = '/02 Fruhneuhochdeutsch early new high/17_cent.xlsx'\n",
    "\n",
    "cent_interaction_validate = {}\n",
    "cent_raw_df = {}\n",
    "\n",
    "for cent, path_net in path_networks_NO_FREQ.items():\n",
    "\n",
    "#     path_net = path_networks['15']\n",
    "    print('------------ Cent:', cent, ' Path:', path_net)\n",
    "\n",
    "    cent_df = pd.read_excel( path_dataset_dir + path_net)\n",
    "    \n",
    "    cent_df = cent_df.drop(columns=[c for c in cent_df.columns if 'Unnamed' in c])\n",
    "    \n",
    "\n",
    "    cent_df.loc[:, ['Source', 'Target', 'Interaction']] = (\n",
    "        cent_df.loc[:, ['Source', 'Target', 'Interaction']].apply(lambda x: x.str.strip(), axis=1)\n",
    "    ) \n",
    "\n",
    "    cent_raw_df[cent] = cent_df.copy()\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    G=nx.from_pandas_edgelist(\n",
    "        cent_df, source='Source', target='Target', \n",
    "        edge_attr=True, create_using=nx.DiGraph()\n",
    "    )\n",
    "    \n",
    "    # nx.draw(G, with_labels=True)\n",
    "    # print(type(G))\n",
    "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "\n",
    "    print('num edges in excel:', len(cent_df), ' num network edges:', G.number_of_edges())\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    cent_df['frequency'] = cent_df['Interaction']\n",
    "\n",
    "    cent_df = (\n",
    "        cent_df.groupby(['Source', 'Target'])\n",
    "        .agg({\n",
    "            'Interaction': lambda x: set([v.upper() for v in x]),\n",
    "            'frequency': np.size,\n",
    "         })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    cent_df['Interaction count'] = cent_df['Interaction'].apply(len)\n",
    "\n",
    "    # print(path_net)\n",
    "    cent_df = cent_df.sort_values(by=['Interaction count', 'frequency'], ascending=False)\n",
    "\n",
    "    if save_freq_files:\n",
    "        path_export = (path_dataset_dir + path_net)[:-5] + '_freq.xlsx'\n",
    "        print('   EXPORTED -->', path_export)\n",
    "        cent_df.to_excel(path_export)\n",
    "    \n",
    "    cent_interaction_validate[cent] = cent_df[cent_df['Interaction count'] > 1]\n",
    "    \n",
    "    print(\n",
    "        'Interaction count > 1 -->', len(cent_interaction_validate[cent])\n",
    "    )\n",
    "    \n",
    "    del cent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE MUST HAVE Only two nodes with multiple edges!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Interaction count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AX werden</td>\n",
       "      <td>PP er</td>\n",
       "      <td>{PP, VP}</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source Target Interaction  frequency  Interaction count\n",
       "379  AX werden  PP er  {PP, VP}    92         2                "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('WE MUST HAVE Only two nodes with multiple edges!')\n",
    "cent_interaction_validate['17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3/29597209#29597209\n",
    "def hierarchy_pos(G, root=None, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "\n",
    "    '''\n",
    "    From Joel's answer at https://stackoverflow.com/a/29597209/2966723.  \n",
    "    Licensed under Creative Commons Attribution-Share Alike \n",
    "    \n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "    \n",
    "    G: the graph (must be a tree)\n",
    "    \n",
    "    root: the root node of current branch \n",
    "    - if the tree is directed and this is not given, \n",
    "      the root will be found and used\n",
    "    - if the tree is directed and this is given, then \n",
    "      the positions will be just for the descendants of this node.\n",
    "    - if the tree is undirected and not given, \n",
    "      then a random choice will be used.\n",
    "    \n",
    "    width: horizontal space allocated for this branch - avoids overlap with other branches\n",
    "    \n",
    "    vert_gap: gap between levels of hierarchy\n",
    "    \n",
    "    vert_loc: vertical location of root\n",
    "    \n",
    "    xcenter: horizontal location of root\n",
    "    '''\n",
    "    if not nx.is_tree(G):\n",
    "        raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = next(iter(nx.topological_sort(G)))  #allows back compatibility with nx version 1.11\n",
    "        else:\n",
    "            root = random.choice(list(G.nodes))\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "    \n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "            \n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenght_all_pairs_shortest_path(G_nx):\n",
    "    q = nx.all_pairs_shortest_path(G_nx)\n",
    "    \n",
    "    p_all = []\n",
    "\n",
    "    for p in q:\n",
    "        p_all.append(p)\n",
    "\n",
    "    p_lenght = []\n",
    "    path_df = []\n",
    "    \n",
    "    for p_2 in [p[1].values() for p in p_all]:\n",
    "        for p3 in p_2:\n",
    "            p_lenght.append(len(p3))\n",
    "            \n",
    "            path_df.append({'l': len(p3), 'p': p3})\n",
    "#         p_lenght += [len(p3) for p3 in p_2]\n",
    "\n",
    "        pass\n",
    "    \n",
    "    path_df = pd.DataFrame(path_df)\n",
    "    path_df['p'] = path_df['p'].astype('str')\n",
    "    \n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Trees: 518 Num NOT trees: 112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diamter directed</th>\n",
       "      <th>diameter indirected</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.050193</td>\n",
       "      <td>4.237452</td>\n",
       "      <td>4.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.150809</td>\n",
       "      <td>1.387840</td>\n",
       "      <td>1.150971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       diamter directed  diameter indirected      height\n",
       "count  518.000000        518.000000           518.000000\n",
       "mean   4.050193          4.237452             4.046332  \n",
       "std    1.150809          1.387840             1.150971  \n",
       "min    2.000000          1.000000             2.000000  \n",
       "25%    3.000000          3.000000             3.000000  \n",
       "50%    4.000000          4.000000             4.000000  \n",
       "75%    5.000000          5.000000             5.000000  \n",
       "max    8.000000          10.000000            8.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_started = False\n",
    "G = None\n",
    "row_num = 0\n",
    "root_row_num_current = None\n",
    "\n",
    "tree_root = None\n",
    "\n",
    "G_list = []\n",
    "G_not_tree_list = []\n",
    "cent = '17'\n",
    "\n",
    "for source, target, is_root in cent_raw_df[cent][['Source', 'Target', 'Root']].to_numpy():\n",
    "    if (sentence_started is True and is_root in [1, -1]) or (row_num == len(cent_raw_df[cent]) - 1):\n",
    "        sentence_started = False\n",
    "        \n",
    "        if(nx.is_tree(G)):\n",
    "            pos = hierarchy_pos(G, root=tree_root)\n",
    "            \n",
    "            path_df = lenght_all_pairs_shortest_path(G)\n",
    "            \n",
    "            G_list.append({\n",
    "                'root':tree_root, \n",
    "                'G': G,\n",
    "                'diamter directed': path_df['l'].max(),\n",
    "                'diameter indirected': nx.diameter(G.to_undirected()),\n",
    "                'height': len(set([v[1] for v in pos.values()]))\n",
    "            })\n",
    "        else:\n",
    "            G_not_tree_list.append((root_row_num_current, G))\n",
    "#             print('not tree')\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    if is_root == 1:\n",
    "        sentence_started = True\n",
    "        root_row_num_current = row_num\n",
    "        tree_root = source\n",
    "        G = nx.DiGraph()\n",
    "        pass\n",
    "    \n",
    "    G.add_edge(source, target)\n",
    "    \n",
    "    row_num += 1\n",
    "    pass\n",
    "\n",
    "print('Num Trees:', len(G_list), 'Num NOT trees:', len(G_not_tree_list))\n",
    "\n",
    "df = pd.DataFrame(G_list)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:28,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fig at:  D:/GoogleDrive/Research/Linguistic project/German/data/not_tree/cent_17_part_0.png\n",
      "Saved fig at:  D:/GoogleDrive/Research/Linguistic project/German/data/not_tree/cent_17_part_1.png\n",
      "Saved fig at:  D:/GoogleDrive/Research/Linguistic project/German/data/not_tree/cent_17_part_2.png\n",
      "Saved fig at:  D:/GoogleDrive/Research/Linguistic project/German/data/not_tree/cent_17_part_3.png\n",
      "Cent: 17\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Export Not trees\n",
    "'''\n",
    "limit_number_nets = 30\n",
    "not_tree_df = []\n",
    "num_not_tree = len(G_not_tree_list)\n",
    "figs = []\n",
    "ax_index = 0\n",
    "\n",
    "for i, not_tree in tqdm(enumerate(G_not_tree_list)):\n",
    "    if i % limit_number_nets == 0:\n",
    "        plt.close()\n",
    "        \n",
    "        fig, axs = plt.subplots(limit_number_nets, figsize=(10, limit_number_nets * 4), dpi=200)\n",
    "        ax_index = 0\n",
    "        \n",
    "        figs.append(fig)\n",
    "        pass\n",
    "\n",
    "    not_tree_df.append({'row_num': row_num + 2, 'cent': cent})\n",
    "    \n",
    "    row_num, G = not_tree   \n",
    "\n",
    "    pos=graphviz_layout(G, prog=['dot', 'twopi', 'sfdp', 'circo'][0])\n",
    "\n",
    "    nx.draw(G, pos=pos, with_labels = True, ax=axs[ax_index])\n",
    "    axs[ax_index].set_title(\n",
    "        '--------------------------------------Row Number: {} ({} from {})--------------------------------------'.format(\n",
    "        row_num + 2,\n",
    "        i + 1,\n",
    "        num_not_tree\n",
    "    ))\n",
    "    \n",
    "    ax_index += 1\n",
    "    pass\n",
    "\n",
    "plt.close()\n",
    "\n",
    "not_tree_df = pd.DataFrame(not_tree_df)\n",
    "not_tree_df.to_excel(path_dataset_dir + 'not_tree/cent_{}.xlsx'.format(cent))\n",
    "\n",
    "for i, fig in enumerate(figs):\n",
    "    path_fig = path_dataset_dir + 'not_tree/cent_{}_part_{}.png'.format(cent, i)\n",
    "    fig.savefig(path_fig, bbox_inches='tight')\n",
    "    print('Saved fig at: ', path_fig)\n",
    "    del fig\n",
    "    pass\n",
    "\n",
    "del figs\n",
    "    \n",
    "print('Cent:', cent)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Visualize a Tree\n",
    "'''\n",
    "# https://stackoverflow.com/questions/57512155/how-to-draw-a-tree-more-beautifully-in-networkx\n",
    "# from networkx.drawing.nx_pydot import graphviz_layout\n",
    "# pos = graphviz_layout(giant, prog=\"circo\")\n",
    "\n",
    "# https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3/29597209#29597209\n",
    "index_tree = [0, 515, 400][0]\n",
    "\n",
    "tree_root = G_list[index_tree]['root']\n",
    "G = G_list[index_tree]['G']\n",
    "\n",
    "pos = hierarchy_pos(G, root=tree_root)\n",
    "\n",
    "nx.draw(G, pos=pos, with_labels = True)\n",
    "\n",
    "# nx.draw(giant, pos=nx.spring_layout(giant), with_labels = True)\n",
    "print('Cent:', cent)\n",
    "print('Tree height:', len(set([v[1] for v in pos.values()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualize a bad Tree\n",
    "'''\n",
    "# https://stackoverflow.com/questions/57512155/how-to-draw-a-tree-more-beautifully-in-networkx\n",
    "# from networkx.drawing.nx_pydot import graphviz_layout\n",
    "# pos = graphviz_layout(giant, prog=\"circo\")\n",
    "\n",
    "# https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3/29597209#29597209\n",
    "index_tree = [0, 515, 400][0]\n",
    "\n",
    "row_number, G = G_not_tree_list[index_tree]\n",
    "\n",
    "pos=graphviz_layout(G, prog=['dot', 'twopi', 'sfdp', 'circo'][0])\n",
    "\n",
    "nx.draw(G, pos=pos, with_labels = True)\n",
    "\n",
    "# nx.draw(giant, pos=nx.spring_layout(giant), with_labels = True)\n",
    "print('Cent:', cent)\n",
    "print('Tree height:', len(set([v[1] for v in pos.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corrected Nets with Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_networks = OrderedDict()\n",
    "\n",
    "path_networks['11'] = \"/01 Mittelhochdeutsch middle high/11_cent_freq.xlsx\" \n",
    "path_networks['12'] = \"/01 Mittelhochdeutsch middle high/12_cent_freq.xlsx\"\n",
    "path_networks['13'] = \"/01 Mittelhochdeutsch middle high/13_cent_freq.xlsx\"\n",
    "path_networks['E14'] = \"/01 Mittelhochdeutsch middle high/14E_cent_freq.xlsx\" # Early\n",
    "\n",
    "path_networks['L14'] = '/02 Fruhneuhochdeutsch early new high/14L_cent_freq.xlsx' # Late\n",
    "path_networks['15'] = '/02 Fruhneuhochdeutsch early new high/15_cent_freq.xlsx'\n",
    "path_networks['16'] = '/02 Fruhneuhochdeutsch early new high/16_cent_freq.xlsx'\n",
    "path_networks['17'] = '/02 Fruhneuhochdeutsch early new high/17_cent_freq.xlsx'\n",
    "\n",
    "path_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_networks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cent_nets = OrderedDict()\n",
    "syntactic_nets = []\n",
    "\n",
    "for cent, path_net in path_networks.items():\n",
    "    print('------- cent:', cent)\n",
    "    \n",
    "    cent_df = pd.read_excel( path_dataset_dir + path_net).drop(columns='Unnamed: 0')\n",
    "    \n",
    "    cent_df['Source'] = cent_df['Source'].str.lower().apply(lambda x: x.split(' ')[0].upper() + ' ' + ' '.join(x.split(' ')[1:]))\n",
    "    cent_df['Target'] = cent_df['Target'].str.lower().apply(lambda x: x.split(' ')[0].upper() + ' ' + ' '.join(x.split(' ')[1:]))\n",
    "    \n",
    "    cent_df.loc[:, 'Source':'Target'] = cent_df.loc[:, 'Source':'Target'].apply(\n",
    "        lambda x: x.str.strip())\n",
    "    \n",
    "#     print(cent_df.columns)\n",
    "    G = nx.from_pandas_edgelist(\n",
    "        cent_df, \n",
    "        source='Source', \n",
    "        target='Target', \n",
    "        edge_attr=True,\n",
    "#         edge_attr=['Interaction', 'frequency', 'Interaction count'], \n",
    "#         Created a directed graph\n",
    "        create_using=nx.DiGraph()\n",
    "    )\n",
    "    \n",
    "    cent_df['cent'] = cent\n",
    "    syntactic_nets.append(cent_df)\n",
    "    \n",
    "    print('n:', G.number_of_nodes(), 'e:', G.number_of_edges())\n",
    "    \n",
    "    cent_nets[cent] = G\n",
    "    pass\n",
    "\n",
    "syntactic_nets = pd.concat(syntactic_nets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    path_syntactic_nets = path_dataset_dir + 'syntactic_nets_german.xlsx'\n",
    "    print(path_syntactic_nets)\n",
    "    syntactic_nets.to_excel(path_syntactic_nets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all_cent = set(syntactic_nets['Source']).union(set(syntactic_nets['Target']))\n",
    "\n",
    "[n for n in nodes_all_cent if 'werden' in n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation | TODO FIX!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntactic_nets.to_csv('german_ling_netwrok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO FIX!\n",
    "The ones with count = 1 seems to have an issue\n",
    "'''\n",
    "\n",
    "cent_interaction_count = syntactic_nets.groupby(['cent', 'Interaction']).agg(count = ('Interaction', np.size))\n",
    "if False:\n",
    "    cent_interaction_count.to_excel('cent_interaction_count.xlsx')\n",
    "    pass\n",
    "\n",
    "cent_interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.get_edge_data('AX werden','PP er')\n",
    "# cent_df\n",
    "# pd.read_excel( path_dataset_dir + path_net)\n",
    "# path_dataset_dir + path_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = lenght_all_pairs_shortest_path(cent_nets['16'])\n",
    "print(path_df['l'].max())\n",
    "sns.histplot(path_df['l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df[path_df['l'] == 17].drop_duplicates('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = lenght_all_pairs_shortest_path(cent_nets['17'])\n",
    "print(path_df['l'].max())\n",
    "sns.histplot(path_df['l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df[path_df['l'] == 17].drop_duplicates('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = lenght_all_pairs_shortest_path(cent_nets['17'])\n",
    "print(path_df['l'].max())\n",
    "sns.histplot(path_df['l'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Hirearchy\n",
    "\n",
    "- using Graph Hierarchy https://github.com/shuaib7860/GraphHierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodal Measures: Hirearchichal Levels\n",
    "- Hierarchical levels is a generalisation of the notion of trophic levels and describes each vertex’s rank with respect to\n",
    "“enegry” or “information” flow.\n",
    "- Influence centrality is a measure of a vertex’s ability to influence the long term state of the graph.\n",
    "- The democracy coefficient measures the feedback that is present in the graph.\n",
    "- The hierarchical incoherence parameter is a straightforward generalisation of trophic incoherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_measures_df = []\n",
    "\n",
    "for cent, G in tqdm(cent_nets.items()):\n",
    "    \n",
    "    tmp_df = pd.concat([\n",
    "            \n",
    "            pd.Series(\n",
    "                list(G.nodes), \n",
    "                name='node'\n",
    "            ),\n",
    "        \n",
    "            pd.Series(\n",
    "                gh.hierarchical_levels(G, weight='frequency'), \n",
    "                name='hierarchical_levels'\n",
    "            )\n",
    "        ], axis=1\n",
    "    )\n",
    "    \n",
    "    tmp_df['cent'] = cent\n",
    "    \n",
    "    f_hierarchical_levels, f_influence_centrality, f_hierarchical_diff_adj_sparse, f_democracy_coefficient, f_hierarchical_incoherence = gh.forward_hierarchical_metrics(G, weight='frequency')\n",
    "    \n",
    "    b_hierarchical_levels, b_influence_centrality, b_hierarchical_diff_adj_sparse, b_democracy_coefficient, b_hierarchical_incoherence = gh.backward_hierarchical_metrics(G, weight='frequency')\n",
    "    \n",
    "    tmp_df['f_hierarchical_levels'] = f_hierarchical_levels\n",
    "    tmp_df['b_hierarchical_levels'] = b_hierarchical_levels\n",
    "    \n",
    "    tmp_df['f_influence_centrality'] = f_influence_centrality\n",
    "    tmp_df['b_influence_centrality'] = b_influence_centrality\n",
    "    \n",
    "    tmp_df['f_democracy_coefficient'] = f_democracy_coefficient\n",
    "    tmp_df['b_democracy_coefficient'] = b_democracy_coefficient\n",
    "    \n",
    "    tmp_df['f_hierarchical_incoherence'] = f_hierarchical_incoherence\n",
    "    tmp_df['b_hierarchical_incoherence'] = b_hierarchical_incoherence\n",
    "    \n",
    "    path_df = lenght_all_pairs_shortest_path(G)\n",
    "    tmp_df['diameter directed'] = path_df['l'].max()\n",
    "\n",
    "    \n",
    "    tmp_df['diameter undirected'] = None\n",
    "    if False:\n",
    "        G_u = G.to_undirected()\n",
    "        Gcc = sorted(nx.connected_components(G_u), key=len, reverse=True)\n",
    "        giant = G_u.subgraph(Gcc[0])\n",
    "        tmp_df['diameter undirected'] = nx.diameter(giant)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    tmp_df = pd.merge(\n",
    "        pd.DataFrame(G.out_degree(), columns=['node', 'out_degree']),\n",
    "        tmp_df,\n",
    "        on='node', how='right'\n",
    "    )\n",
    "    \n",
    "    tmp_df = pd.merge(\n",
    "        pd.DataFrame(G.in_degree(), columns=['node', 'in_degree']),\n",
    "        tmp_df,\n",
    "        on='node', how='right'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    h_measures_df.append(tmp_df)\n",
    "    \n",
    "    del path_df\n",
    "#     break\n",
    "    pass\n",
    "    \n",
    "h_measures_df = pd.concat(h_measures_df).reset_index(drop=True)\n",
    "len(h_measures_df)\n",
    "\n",
    "cent_to_num = {\n",
    "    '11': 11.0, '12': 12.0, '13': 13.0, 'E14': 14.1, 'L14': 14.2, '15': 15.0, '16': 16.0, '17': 17.0\n",
    "}\n",
    "\n",
    "h_measures_df['cent_num'] = h_measures_df['cent'].map(cent_to_num)\n",
    "# cent_to_num\n",
    "\n",
    "h_measures_df.insert(1, 'node func', h_measures_df['node'].apply(lambda x: x.split(' ')[0]))\n",
    "h_measures_df.insert(4, 'degree', h_measures_df['in_degree'] + h_measures_df['out_degree'])\n",
    "\n",
    "h_measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CORRELATION TEST\n",
    "https://realpython.com/numpy-scipy-pandas-correlation-python/\n",
    "'''\n",
    "\n",
    "col_1 = ['', 'in_degree', 'out_degree', 'degree'][1]\n",
    "col_2 = ['',\n",
    "    'f_hierarchical_levels', 'b_hierarchical_levels', 'hierarchical_levels',\n",
    "    'f_influence_centrality', 'b_influence_centrality'\n",
    "][1]\n",
    "\n",
    "print('Spearmanr Correlation between \"{}\" and \"{}\"'.format(col_1, col_2))\n",
    "\n",
    "for cent_num in h_measures_df['cent_num'].unique():\n",
    "    df = h_measures_df[h_measures_df['cent_num'] == cent_num]\n",
    "\n",
    "    print('cent: {} | {}'.format(cent_num, stats.spearmanr(df[col_1], df[col_2])))\n",
    "# diameter\n",
    "\n",
    "print('cent: ALL | {}'.format(stats.spearmanr(h_measures_df[col_1], h_measures_df[col_2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ANOTHER VALIDATION\n",
    "TODO NOTE: add a column to check number of times function is used\n",
    "'''\n",
    "\n",
    "func_frac_df = h_measures_df.groupby(['node func', 'cent']).agg(node_count_func = ('node func', np.size))\n",
    "\n",
    "func_frac_df['node frac'] = func_frac_df['node_count_func'] / len(h_measures_df)\n",
    "\n",
    "# dunc_frac_df.to_excel('node_func_possible_more_bugs.xlsx')\n",
    "\n",
    "func_frac_df.sort_values(by='node frac', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_measures_df\n",
    "\n",
    "# f_democracy_coefficient\n",
    "\n",
    "h_measures_df[h_measures_df['f_influence_centrality'] > 0.1][['node', 'cent', 'f_influence_centrality', 'f_hierarchical_levels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    h_measures_df.to_excel(path_dataset_dir + 'hierarchical_metrics_german.xlsx')\n",
    "    \n",
    "if False:\n",
    "    h_measures_df = pd.read_excel(path_dataset_dir + 'hierarchical_metrics_german.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h_measures_df['cent'].value_counts())\n",
    "h_measures_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hirearchy_measure_single_cent(h_measures_df, cent, binwidth, figsize):\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 12\n",
    "    BIGGER_SIZE = 12\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    matplotlib.rcParams['font.serif'] = \"Times New Roman\"\n",
    "    matplotlib.rcParams['font.family'] = \"serif\"\n",
    "    sns.set_style({'font.family':'serif', 'font.serif':'Times New Roman'})\n",
    "\n",
    "    plt.figure(figsize=figsize, dpi=150)\n",
    "\n",
    "    h_levels_tmp = h_measures_df[h_measures_df['cent'] == cent]\n",
    "\n",
    "    g = sns.histplot(\n",
    "        data=h_levels_tmp, x='f_hierarchical_levels', binwidth=binwidth\n",
    "    )\n",
    "    \n",
    "    g.set_title('{} Century - Forward Hierarchical Levels | binwidth: {}'.format(cent, binwidth), loc='center')\n",
    "    g.set(xlabel='', ylabel='', xlim=(-4, 4))\n",
    "    \n",
    "    g.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    g.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    \n",
    "    \n",
    "    g.yaxis.set_major_locator(plt.MultipleLocator(50))\n",
    "    g.yaxis.set_minor_locator(plt.MultipleLocator(10))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pass\n",
    "\n",
    "plot_hirearchy_measure_single_cent(h_measures_df=h_measures_df, binwidth=0.1, cent='13', figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_hirearchy_measure(h_measures_df, binwidth, func_names, ylim_dict=None):\n",
    "    SMALL_SIZE = 18\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 28\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    matplotlib.rcParams['font.serif'] = \"Times New Roman\"\n",
    "    matplotlib.rcParams['font.family'] = \"serif\"\n",
    "    sns.set_style({'font.family':'serif', 'font.serif':'Times New Roman'})\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=len(cent_nets.keys()), ncols=2, constrained_layout=True,\n",
    "        sharex=False, sharey=True, dpi=100, figsize=(20, 25))\n",
    "\n",
    "    fig.suptitle('{} | binwidth: {}'.format(\n",
    "        ' & '.join(func_names).replace('_', ' ').title(), binwidth\n",
    "    ))\n",
    "    \n",
    "    cents = list(cent_nets.keys())\n",
    "    \n",
    "    for row, cent in tqdm(enumerate(cents)):\n",
    "\n",
    "        h_levels_tmp = h_measures_df[h_measures_df['cent'] == cent]\n",
    "\n",
    "        g = sns.histplot(\n",
    "            data=h_levels_tmp, x=func_names[0],\n",
    "            ax=axes[row, 0], binwidth=binwidth\n",
    "        )\n",
    "        \n",
    "        g.set_title('{}'.format(cent), loc='center')\n",
    "        \n",
    "        g.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "        \n",
    "        # write xlabel only for last plot in column\n",
    "        if cent != cents[-1]:\n",
    "            g.set(xlabel='')\n",
    "        \n",
    "        if False:\n",
    "            g.set(ylim=(0, ylim_dict[binwidth]) #, xlim=(0, 1), \n",
    "                  #xlabel=covars_latex_dicts[x_col], ylabel=covars_latex_dicts[y_col]\n",
    "            )\n",
    "            pass\n",
    "#         g.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "#         g.yaxis.set_major_locator(plt.MultipleLocator(100))\n",
    "#         print(ylim_dict[binwidth])\n",
    "        '''-------------------------------'''\n",
    "        g = sns.histplot(\n",
    "            data=h_levels_tmp, x= func_names[1],\n",
    "            ax=axes[row, 1], binwidth=binwidth\n",
    "        )\n",
    "        g.set_title('{}'.format(cent), loc='center')\n",
    "        \n",
    "        g.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "        \n",
    "        # write xlabel only for last plot in column\n",
    "        if cent != cents[-1]:\n",
    "            g.set(xlabel='')\n",
    "        \n",
    "        if False:\n",
    "            g.set(ylim=(0, ylim_dict[binwidth]) #, xlim=(0, 1), \n",
    "                  #xlabel=covars_latex_dicts[x_col], ylabel=covars_latex_dicts[y_col]\n",
    "            )\n",
    "            pass\n",
    "#         g.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "#         g.yaxis.set_major_locator(plt.MultipleLocator(100))\n",
    "\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "binwidth = [0.1, None][0]\n",
    "# func_name = ['hierarchical_levels', 'forward_hierarchical_levels'][1]\n",
    "func_names = [\n",
    "    ('hierarchical_levels', 'f_hierarchical_levels'),\n",
    "    ('hierarchical_levels', 'b_hierarchical_levels'),\n",
    "    ('f_hierarchical_levels', 'b_hierarchical_levels'),\n",
    "    \n",
    "#     ('f_influence_centrality', 'f_hierarchical_levels')\n",
    "][-1]\n",
    "# ylim_dicts={\n",
    "#     ('forward_hierarchical_levels weighted', 'backward_hierarchical_levels weighted'): {\n",
    "#         0.25:300, 0.5: 250, 0.75: 300, 1.0: 350, None: 400},\n",
    "#     ('hierarchical_levels weighted', 'forward_hierarchical_levels weighted'): {None: 400},\n",
    "#     ('hierarchical_levels weighted', 'backward_hierarchical_levels weighted'): {None: 400},\n",
    "# }\n",
    "\n",
    "plot_hirearchy_measure(h_measures_df=h_measures_df, \n",
    "                       binwidth=binwidth, \n",
    "#                        ylim_dict=ylim_dicts[func_names], \n",
    "                       func_names=func_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measures_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cen = '11'\n",
    "# plt.figure(figsize=(15,8))\n",
    "# sns.histplot(data=h_measures_df[h_measures_df['cent'] == cent], x='f_influence_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measures_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measures_df['cent_FHL'] = h_measures_df.apply(lambda r: (r['cent'], round(r['f_hierarchical_levels'], 3)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_FHL_df = (\n",
    "    h_measures_df\n",
    "    .groupby('node')\n",
    "    .agg(\n",
    "        FHL_avg=('f_hierarchical_levels', np.mean), \n",
    "        FHL_std=('f_hierarchical_levels', np.std), \n",
    "        count_cent=('cent', np.size),\n",
    "        cent_FHL=('cent_FHL', lambda x: list(x))\n",
    "    )\n",
    "    .sort_values(by='FHL_std', ascending=False)\n",
    ")\n",
    "\n",
    "if True:\n",
    "    nodes_FHL_df.to_excel('nodes_FHL_df.xlsx')\n",
    "    \n",
    "nodes_FHL_df[nodes_FHL_df.index == 'N geist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of nodes exists only single century (std=0):', sum(nodes_FHL_df['FHL_std'].isnull()), 'from', len(nodes_FHL_df))\n",
    "\n",
    "for r in reversed(np.arange(0.5, 2.1, 0.25)):\n",
    "\n",
    "    print('Number of Nodes with std >= {}: {} from {} | Exists in {} centuries'.format(\n",
    "        r,\n",
    "        sum(nodes_FHL_df['FHL_std'] >= r),\n",
    "        sum(~nodes_FHL_df['FHL_std'].isnull()),\n",
    "        round(nodes_FHL_df[nodes_FHL_df['FHL_std'] >= r]['count_cent'].mean(), 2)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Forward'''\n",
    "heads_f_influence_centrality = h_measures_df[h_measures_df['f_influence_centrality'] > 0.1].groupby(['node', 'cent']).agg(count = ('cent', np.size))\n",
    "\n",
    "head_f_influence = (\n",
    "    heads_f_influence_centrality\n",
    "    .reset_index()\n",
    "    .pivot(index=['node'], columns='cent', values='count')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "head_f_influence['sum'] = head_f_influence.sum(axis=1)\n",
    "\n",
    "head_f_influence = head_f_influence.sort_values(by=['sum'], ascending=False)\n",
    "\n",
    "if True:\n",
    "    head_f_influence.to_excel(path_dataset_dir + 'influence_cent_forward_high_0.1.xlsx')\n",
    "\n",
    "head_f_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Backward'''\n",
    "heads_f_influence_centrality = h_measures_df[h_measures_df['b_influence_centrality'] > 0.1].groupby(['node', 'cent']).agg(count = ('cent', np.size))\n",
    "\n",
    "head_f_influence = (\n",
    "    heads_f_influence_centrality\n",
    "    .reset_index()\n",
    "    .pivot(index=['node'], columns='cent', values='count')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "head_f_influence['sum'] = head_f_influence.sum(axis=1)\n",
    "\n",
    "head_f_influence = head_f_influence.sort_values(by=['sum'], ascending=False)\n",
    "\n",
    "if True:\n",
    "    head_f_influence.to_excel(path_dataset_dir + 'influence_cent_backward_high_0.1.xlsx')\n",
    "\n",
    "head_f_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n in nodes_all_cent if 'werden' in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "ax = sns.scatterplot(data=h_measures_df, x='f_influence_centrality', y='b_influence_centrality', \n",
    "                     hue='cent_num', alpha=0.2, linewidth=0, legend='full')\n",
    "\n",
    "ax.set(xscale='log', yscale='log')\n",
    "\n",
    "# h_measures_df['f_influence_centrality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "measure = ['f_influence_centrality'][0]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.boxplot(data=h_measures_df, y=measure, x='cent')\n",
    "ax.set(yscale=\"log\")\n",
    "ax.set_title(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(data=h_measures_df, x='f_hierarchical_levels', hue='cent_num', binwidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(data=h_measures_df, x='b_hierarchical_levels', hue='cent_num', binwidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(data=h_measures_df, x='hierarchical_levels', hue='cent_num', binwidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.histplot(data=h_levels_df, x='hierarchical_levels NOT weighted', hue='cent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sns.histplot(\n",
    "#     data=h_levels_df[h_levels_df['cent'].isin(['11', '17'])], \n",
    "#     x='hierarchical_levels', hue='cent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data=h_levels_df, x='hierarchical_levels', hue='cent')\n",
    "\n",
    "fig = px.histogram(h_levels_df, x=\"hierarchical_levels weighted\", color=\"cent\", barmode=\"overlay\")\n",
    "\n",
    "fig.update_xaxes(range=[-9, +12], autorange=False)\n",
    "fig.update_yaxes(range=[0, 110], autorange=False)\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "pio.show(fig, renderer='browser', validate=True)\n",
    "# fig.write_html(file_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Measures: Democracy Coeff and Hierarchical Incoherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %config Completer.use_jedi = False\n",
    "# G.nodes\n",
    "h_measures_df[h_measures_df['node'] == 'IV werden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges[('AX werden', 'IV erben')]\n",
    "gh.node_backward_influence_centrality(G, 'IV werden', weight='frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_forw_df = []\n",
    "\n",
    "for cent, G in tqdm(cent_nets.items()):\n",
    "    FHD_adj, FHD_mean, FHD_std = gh.forward_hierarchical_incoherence(G, weight='frequency')\n",
    "    \n",
    "#     b_hierarchical_level_vector, b_influence_centrality_vector, b_hierarchical_diff_adj_sparse, b_democracy_coefficient, b_hierarchical_incoherence = gh.backward_hierarchical_metrics(G, weight='frequency')\n",
    "    \n",
    "    hierarchical_level_vector, influence_centrality_vector, hierarchical_diff_adj_sparse, democracy_coefficient, hierarchical_incoherence = gh.forward_hierarchical_metrics(G, weight='frequency')\n",
    "    \n",
    "    dem_forw_df.append(\n",
    "        {\n",
    "            'cent': cent,\n",
    "            'forward_hierarchical_incoherence avg': FHD_mean,\n",
    "            'forward_hierarchical_incoherence std': FHD_std,\n",
    "            'forward_democracy_coefficient': gh.forward_democracy_coefficient(\n",
    "                G, weight='frequency'),\n",
    "            'backward_democracy_coefficient': gh.backward_democracy_coefficient(\n",
    "                G, weight='frequency'),\n",
    "            'democracy_coefficient': democracy_coefficient,\n",
    "            'hierarchical_incoherence': hierarchical_incoherence\n",
    "        }\n",
    "    )\n",
    "    \n",
    "dem_forw_df = pd.DataFrame(dem_forw_df)\n",
    "dem_forw_df['cent_num'] = dem_forw_df['cent'].map(cent_to_num)\n",
    "dem_forw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "sns.scatterplot(data=dem_forw_df, x=\"hierarchical_incoherence\", y=\"democracy_coefficient\", hue='cent',\n",
    "               s=100, legend='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_forw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cent\", y=\"forward_hierarchical_incoherence std\", data=dem_forw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'UNWEIGHTED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cent\", y=\"forward_democracy_coefficient\", data=dem_forw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_forw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"cent\", y=\"backward_democracy_coefficient\", data=dem_forw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "- https://stackoverflow.com/questions/57458789/get-bin-width-used-for-seaborn-plot\n",
    "- ITS SO GOOD: https://jakevdp.github.io/PythonDataScienceHandbook/04.10-customizing-ticks.html\n",
    "- https://stackoverflow.com/questions/56605113/how-to-set-x-axis-ticklabels-in-a-seaborn-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OLD] yFiles Hierarchical Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_yfiles_layout = 'D:/GoogleDrive/Research/Linguistic project/German/data/Hierarchical Layout yfiles/'\n",
    "\n",
    "path_networks = OrderedDict()\n",
    "\n",
    "path_networks['11'] = path_yfiles_layout + \"/Cent11.cyjs\" \n",
    "path_networks['12'] = path_yfiles_layout + \"/Cent12.cyjs\" \n",
    "path_networks['13'] = path_yfiles_layout + \"/Cent13.cyjs\" \n",
    "path_networks['14E'] = path_yfiles_layout + \"/Cent14E.cyjs\" \n",
    "\n",
    "path_networks['14L'] = path_yfiles_layout + \"/Cent14L.cyjs\" \n",
    "path_networks['15'] = path_yfiles_layout + \"/Cent15.cyjs\" \n",
    "path_networks['16'] = path_yfiles_layout + \"/Cent16.cyjs\" \n",
    "path_networks['17'] = path_yfiles_layout + \"/Cent17.cyjs\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layouts = OrderedDict()\n",
    "cen_layers = {}\n",
    "\n",
    "for cent, path_layout in path_networks.items():\n",
    "    f = open(path_layout, \"r\", encoding='utf-8')\n",
    "    layouts[cent] = json.loads(f.read())\n",
    "    \n",
    "    cen_layers[cent] = []\n",
    "    \n",
    "    for node in layouts[cent]['elements']['nodes']:\n",
    "        \n",
    "        cen_layers[cent].append({\n",
    "            'name': node['data']['name'],\n",
    "            'x': node['position']['x'],\n",
    "            'y': node['position']['y'],\n",
    "            'y_round': round(node['position']['y'])\n",
    "        })\n",
    "        pass\n",
    "    \n",
    "    cen_layers[cent] = pd.DataFrame(cen_layers[cent])\n",
    "    \"\"\"Now convert unique y value to sequential layer number\"\"\"\n",
    "    map_y_val_to_layer_num = {\n",
    "        y: l + 1 for l, y in enumerate(sorted(set(cen_layers[cent]['y_round'])))\n",
    "    }\n",
    "    \n",
    "    cen_layers[cent]['layer'] = cen_layers[cent]['y_round'].map(map_y_val_to_layer_num)\n",
    "    \n",
    "    cen_layers[cent] = cen_layers[cent].sort_values('layer').reset_index(drop=True)\n",
    "#     break\n",
    "    pass\n",
    "# del layers\n",
    "map_y_val_to_layer_num\n",
    "cen_layers['17'].columns\n",
    "# cen_layers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_layer_count = []\n",
    "for cen, cen_layer in cen_layers.items():\n",
    "    cen_layer_count.append({\n",
    "        'cent': cen,\n",
    "        'num layers': cen_layer['layer'].max()\n",
    "    })\n",
    "    pass\n",
    "\n",
    "cen_layer_count = pd.DataFrame(cen_layer_count)\n",
    "\n",
    "cen_layers['cen_layer_count'] = cen_layer_count\n",
    "\n",
    "cen_layers['cen_layer_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax=sns.barplot(x=\"cent\", y=\"num layers\", data=cen_layer_count)\n",
    "ax.set(ylim=(0, 30), title='Number of Layers in Each Century')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xls(dfs_dict=cen_layers, \n",
    "         xls_path=path_yfiles_layout + '/all_cent_layers_yfiles.xlsx', \n",
    "         open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OLD] Graph Hierarchy \n",
    "- How to draw netwrokx graph https://faculty.math.illinois.edu/~hirani/cbmg/graphs.html\n",
    "- Add x-y axis when drawing with NetworkX https://stackoverflow.com/questions/56994061/how-to-make-x-and-y-axes-appear-when-using-networkx-and-matplotlib\n",
    "- A cool toturial for visualization https://www.datacamp.com/community/tutorials/networkx-python-graph-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = nx.gnr_graph(20, 0.4)\n",
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(zip(\n",
    "    graph.nodes(),\n",
    "#     gh.forward_hierarchical_levels(graph)\n",
    "    gh.hierarchical_levels(graph)\n",
    "))\n",
    "\n",
    "l.sort(key=lambda x: x[1])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level_dict = {}\n",
    "level_num = 0\n",
    "prev_layer_level = None\n",
    "offset = 0\n",
    "\n",
    "for node, level in l:\n",
    "    if prev_layer_level is not None:\n",
    "        offset = 1 - (level - prev_layer_level)\n",
    "    \n",
    "#     print('l: ', level, 'o: ', offset)\n",
    "    \n",
    "    if level not in level_dict:\n",
    "        level_dict[level] = []\n",
    "        level_num += 1\n",
    "        prev_layer_level = level\n",
    "        pass\n",
    "    \n",
    "    level_dict[level].append(node)\n",
    "#     print(level + (np.sign(level) * 1))\n",
    "    graph.nodes[node]['pos'] = (\n",
    "        (len(level_dict[level]) * 2) + random.uniform(-1, 1),\n",
    "        level \n",
    "    )\n",
    "    pass\n",
    "\n",
    "# plt.figure(3,figsize=(12,12)) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_dpi(150)\n",
    "fig.set_size_inches(10,10)\n",
    "pos=nx.get_node_attributes(graph,'pos')\n",
    "\n",
    "plt.figure(3,figsize=(12,12)) \n",
    "\n",
    "nx.draw_networkx(graph, pos, ax=ax)\n",
    "\n",
    "ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('levels: ', len(level_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_l_dict = dict(l)\n",
    "node_l_dict[0] - node_l_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gh.forward_hierarchical_differences(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hierarchical_differences_sparse, \n",
    " hierarchical_differences_mean, \n",
    " hierarchical_differences_std) = gh.forward_hierarchical_incoherence(graph)\n",
    "\n",
    "\"\"\"The standard deviation of the distribution is known as the forward hierarchical incoherence and is an important metric which gives a measure of a network's organisation and structure.\"\"\"\n",
    "print('mean:', hierarchical_differences_mean, 'std:' , hierarchical_differences_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.forward_democracy_coefficient(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in graph.nodes:\n",
    "    print(node, gh.node_forward_influence_centrality(graph, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.forward_influence_centrality(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.hierarchical_levels(graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ling",
   "language": "python",
   "name": "ling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
